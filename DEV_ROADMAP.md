# Queer-AI Rebuild â€¢ End-to-End Roadmap  
*(All-OpenAI stack, <2-min video output, solo-dev workflow)*

---

## ğŸ“œ Legend & Conventions
| Emoji | Meaning |
|-------|---------|
| ğŸ› ï¸  | code task |
| ğŸ¨  | prompt / content task |
| ğŸ”— | external API wiring |
| ğŸ³ | Docker / infra |
| âœ… | completion criteria checkpoint |

**Branch naming:** `phase-<n>-<slug>` &nbsp;|&nbsp; **Commit style:** `<scope>: <imperative summary>`  
Example: `backend: add gpt-4o-mini prompt builder`.

---

## Phase 0 â€“ Project Bootstrap
### Goals
* Scaffold Next 14 + Tailwind app.
* Commit Dockerfile with Node 20-alpine, `ffmpeg`, `yt-dlp`, and `pnpm`.
* Add Upstash Redis & BullMQ queue skeleton.

### Tasks
1. ğŸ› ï¸ `npx create-next-app@latest queer-ai --ts --tailwind --eslint`
2. ğŸ³ Write `Dockerfile`  
   ```Dockerfile
   FROM node:20-alpine
   RUN apk add --no-cache ffmpeg yt-dlp
   WORKDIR /app
   COPY . .
   RUN pnpm install
   CMD ["pnpm","dev"]
   ```
3. ğŸ› ï¸ Init env vars in `.env.example`.
4. ğŸ”— Add Upstash Redis URL + BullMQ `videoQueue`.
5. ğŸ› ï¸ Pre-commit Husky + lint-staged.

### âœ… Done when
* `docker compose up` â‡’ local dev server at `localhost:3000`.
* Empty queue visible in Upstash dashboard.

---

## Phase 1 â€“ Core AI Commentary (Text-only MVP)
### Goals
Generate multi-agent dialogue from a hard-coded transcript snippet.

### Tasks
1. ğŸ› ï¸ Create `/api/generate` route.
2. ğŸ¨ Build `promptBuilder.ts` with personas & format:
   ```
   FabOne: line
   FabTwo: line
   ```
3. ğŸ”— Call **OpenAI Responses API** (`gpt-4o-mini`) with dummy frame array `[]` and dummy transcript summary.
4. ğŸ› ï¸ Parse response â†’ array of `{speaker, text}`.
5. ğŸ› ï¸ Simple front-end page: textarea for â€œTranscript (dev only)â€ + â€œGenerateâ€ button â†’ renders dialogue.

### âœ… Done when
* Input stub transcript, receive â‰¤280-token dialogue with 3+ labelled speakers.

---

## Phase 2 â€“ Audio API (TTS) Integration
### Goals
Turn the dialogue into a single WAV.

### Tasks
1. ğŸ”— Loop lines â†’ **OpenAI Audio TTS** (`tts-1`) with `voice=alloy,fable,â€¦`.
2. ğŸ› ï¸ Write `mergeAudio.ts` using `ffmpeg concat demuxer`.
3. ğŸ› ï¸ Upload merged WAV to `/public/out.wav` (dev only).
4. ğŸ› ï¸ Front-end audio player component.

### âœ… Done when
* Clicking *Generate* gives a playable WAV that speaks every line in order, voices match speakers.

---

## Phase 3 â€“ Video Pipeline (â‰¤120 s, Local FFmpeg)
### Goals
Create MP4: muted clips + AI voiceover.

### Tasks
1. ğŸ”— Use `yt-dlp` to fetch & clip **max 240 s** of source video.
2. ğŸ› ï¸ Sample frames every 5 s â†’ buffer; store file paths.
3. ğŸ› ï¸ `ffmpegCompose.ts`  
   ```
   - mute original
   - pad background volume 0.05
   - overlay voice.wav
   - -t <targetLen>
   ```
4. ğŸ³ Ensure ffmpeg binary works in container.
5. ğŸ› ï¸ Persist `out.mp4` â†’ Cloudflare R2 (signed URL 24 h).

### âœ… Done when
* Given any YouTube link <10 min, pipeline returns signed MP4 in â‰¤45 s locally.

---

## Phase 4 â€“ Async Queue & Progress UX
### Goals
Non-blocking UX, visible status.

### Tasks
1. ğŸ› ï¸ Move heavy work into `worker.ts` (BullMQ consumer).
2. ğŸ”— API route pushes job â†’ returns `jobId`.
3. ğŸ› ï¸ `/api/status?id=â€¦` returns `{progress:0-100,url?:string}`.
4. ğŸ› ï¸ Front-end poll every 2 s â†’ radial progress.

### âœ… Done when
* Browser never times out; progress bar reaches 100 % then auto-plays the video.

---

## Phase 5 â€“ Production Hardening
### Goals
Ship to prod, keep costs & latency predictable.

### Tasks
1. ğŸ› ï¸ Env-switch OpenAI models:  
   *Default:* `gpt-4o-mini`, `tts-1`  
   *Premium toggle:* `gpt-4o`, `tts-1-hd`
2. ğŸ³ GitHub Actions â†’ build & push Docker image â†’ Fly.io.
3. ğŸ”— Budget caps via OpenAI Usage API; abort if >$0.25/job.
4. ğŸ› ï¸ Sentry for backend + Vercel analytics for front-end.
5. ğŸ³ Optional Shotstack fallback: if queue lag > 5 jobs, POST edit JSON â†’ poll render URL.

### âœ… Done when
* End-to-end cold start in prod â‰¤60 s, cost logged â‰¤$0.15/job.
* Premium path verified with toggle.

---

## Phase 6 â€“ User Management & Monetization (Optional)
### Goals
Auth, credit system, Stripe checkout.

_(Skip until productâ€“market fit proven)_

---

## Appendix A â€“ Cost / Latency Table (per 2-min job)

| Step | Model | $ | sec |
|------|-------|---|-----|
| Vision+Text | gpt-4o-mini | 0.05 | 4 |
| TTS (300 tokens) | tts-1 | 0.005 | 6 |
| Whisper STT | whisper-1 | 0.006 | 4 |
| FFmpeg encode | local CPU | ~0 | 20 |
| **Total** |   | **â‰ˆ $0.07** | **~34 s** |

Premium path ~2.3Ã— cost, +4â€“6 s latency.

---

## Appendix B â€“ `.env.example`
```
OPENAI_API_KEY=
NEXT_PUBLIC_APP_URL=http://localhost:3000
REDIS_URL=
R2_ACCESS_KEY_ID=
R2_SECRET_ACCESS_KEY=
R2_BUCKET=
```

---

Happy building!  
Tag issues with `ğŸš§` emoji to track blockers, and use GitHub Projects Â«Phased BoardÂ» to drag tasks into *To Do â†’ In Progress â†’ Done*.
]